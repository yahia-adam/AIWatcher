# Cours complet BeautifulSoup - Web Scraping avec Python

## üìö Introduction

BeautifulSoup est une biblioth√®que Python qui permet de parser et naviguer dans du HTML/XML. Elle facilite l'extraction de donn√©es depuis des pages web.

### Installation

```bash
pip install beautifulsoup4
```

### Import de base
```python
from bs4 import BeautifulSoup
import requests
```

---

## üéØ 1. Cr√©ation et parsing d'un objet BeautifulSoup

### Depuis une cha√Æne HTML

```python
html_doc = """<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>
<p class="story">Once upon a time there were three little sisters...</p>
</body></html>"""

soup = BeautifulSoup(html_doc, "html.parser")
```

### Depuis une page web

```python
response = requests.get('https://example.com')
soup = BeautifulSoup(response.content, 'html.parser')
```

---

## üîç 2. S√©lecteurs CSS - Les m√©thodes de recherche

### 2.1 S√©lection par tag HTML

```python
# Premier √©l√©ment
soup.find('div')           # Premier div
soup.div                    # Raccourci pour le premier div

# Tous les √©l√©ments
soup.find_all('div')       # Tous les divs
soup.find_all(['div', 'p']) # Divs et paragraphes
```

### 2.2 S√©lection par classe CSS

```python
# Un √©l√©ment avec une classe sp√©cifique
soup.find('div', class_='content')

# Tous les √©l√©ments avec une classe
soup.find_all('div', class_='item')

# S√©lecteur CSS
soup.select('.content')     # √âquivalent CSS
soup.select('div.content')  # Tag + classe
```

### 2.3 S√©lection par ID

```python
# Par ID
soup.find('div', id='main')
soup.find('div', {'id': 'main'})  # Alternative avec dict

# S√©lecteur CSS
soup.select('#main')
```

### 2.4 S√©lection par attributs

```python
# Attribut href
soup.find('a', href='https://example.com')

# Attribut src
soup.find('img', {'src': 'image.jpg'})

# Attributs multiples
soup.find('a', href=True, class_='link')
```

---

## üå≥ 3. Navigation dans l'arbre DOM

### 3.1 Relations parent-enfant

```python
# Parents
element.parent              # √âl√©ment parent direct
element.parent.name         # Nom du tag parent
element.parents             # Tous les parents (g√©n√©rateur)

# Enfants
element.children            # Enfants directs (g√©n√©rateur)
element.descendants         # Tous les descendants
element.find_children()     # Enfants avec crit√®res
```

### 3.2 Relations entre fr√®res

```python
# Fr√®res
element.next_sibling        # Fr√®re suivant
element.previous_sibling    # Fr√®re pr√©c√©dent
element.next_siblings       # Tous les fr√®res suivants
element.previous_siblings   # Tous les fr√®res pr√©c√©dents
```

### 3.3 Navigation directe

```python
# Navigation cha√Æn√©e
soup.body.div              # Body > premier div
soup.html.head.title       # HTML > head > title
soup.body.div.p            # Body > div > premier p
```

---

## üìù 4. Extraction de contenu

### 4.1 Extraction de texte

```python
# M√©thodes d'extraction de texte
element.text               # Tout le texte (avec espaces)
element.get_text()         # M√™me chose que .text
element.get_text(strip=True)  # Texte sans espaces superflus
element.string             # Texte direct (sans enfants)
element.stripped_strings   # Liste des cha√Ænes nettoy√©es
```

### 4.2 Extraction d'attributs

```python
# Acc√®s aux attributs
element['href']            # Valeur de l'attribut href
element.get('src')         # Plus s√ªr (retourne None si absent)
element.get('src', 'default.jpg')  # Valeur par d√©faut
element.attrs              # Tous les attributs (dict)
```

### 4.3 Extraction de HTML

```python
# HTML
element.prettify()         # HTML format√© et indent√©
str(element)               # HTML brut
element.encode()           # HTML encod√©
```

---

## üîé 5. Recherche avanc√©e

### 5.1 Recherche avec fonctions

```python
# Recherche de texte contenant un mot
soup.find_all(text=lambda text: 'python' in text.lower())

# Recherche d'√©l√©ments avec conditions
soup.find_all('div', class_=lambda x: x and 'content' in x)
```

### 5.2 Recherche avec expressions r√©guli√®res

```python
import re

# Texte contenant des ann√©es
soup.find_all(text=re.compile(r'\b\d{4}\b'))

# Liens avec pattern sp√©cifique
soup.find_all('a', href=re.compile(r'^https://'))
```

### 5.3 Recherche combin√©e

```python
# Limite de r√©sultats
soup.find_all('div', class_='item', limit=5)

# Recherche dans une zone sp√©cifique
main_div = soup.find('div', id='main')
links = main_div.find_all('a')  # Liens seulement dans main
```

---

## üõ†Ô∏è 6. Modification du DOM

### 6.1 Modification de contenu

```python
# Modifier le texte
element.string = "Nouveau texte"

# Modifier les attributs
element['class'] = 'nouvelle-classe'
element['id'] = 'nouvel-id'
```

### 6.2 Ajout d'√©l√©ments

```python
# Cr√©er un nouveau tag
new_tag = soup.new_tag('div')
new_tag.string = "Contenu du nouveau div"

# Ajouter √† un √©l√©ment
element.append(new_tag)
element.insert(0, new_tag)  # Ins√©rer au d√©but
```

### 6.3 Suppression d'√©l√©ments

```python
# Supprimer un √©l√©ment
element.decompose()        # Supprime l'√©l√©ment du DOM
element.extract()          # Extrait l'√©l√©ment (peut √™tre r√©utilis√©)
element.clear()            # Vide le contenu mais garde le tag
```

---

## üí° 7. Exemples pratiques courants

### 7.1 Extraction de liens

```python
# Extraire tous les liens avec leur texte
links = soup.find_all('a')
for link in links:
    href = link.get('href')
    text = link.get_text().strip()
    print(f"{text}: {href}")
```

### 7.2 Extraction de tableaux
```python

# Extraire le contenu des tableaux
tables = soup.find_all('table')
for table in tables:
    rows = table.find_all('tr')
    for row in rows:
        cells = row.find_all(['td', 'th'])
        row_data = [cell.get_text().strip() for cell in cells]
        print('\t'.join(row_data))
```

### 7.3 Extraction de listes

```python
# Extraire les √©l√©ments de listes
lists = soup.find_all(['ul', 'ol'])
for list_elem in lists:
    items = list_elem.find_all('li')
    for item in items:
        print(f"- {item.get_text().strip()}")
```

### 7.4 Recherche de contenu sp√©cifique

```python
# Trouver des articles avec un mot-cl√©
articles = soup.find_all('article')
for article in articles:
    title = article.find('h1') or article.find('h2')
    if title and 'python' in title.get_text().lower():
        print(f"Article trouv√©: {title.get_text()}")
```

---

## ‚ö†Ô∏è 8. Gestion des erreurs et bonnes pratiques

### 8.1 V√©rification d'existence

```python
# V√©rifier si un √©l√©ment existe
title = soup.find('title')
if title:
    print(title.get_text())
else:
    print("Pas de titre trouv√©")

# V√©rifier les attributs de mani√®re s√ªre
link = soup.find('a')
href = link.get('href', '')  # Valeur par d√©faut si href n'existe pas
```

### 8.2 Gestion des cas particuliers

```python
# √âviter les erreurs avec des √©l√©ments None
element = soup.find('div', class_='inexistant')
if element:
    text = element.get_text()
else:
    text = "√âl√©ment non trouv√©"
```

### 8.3 Performance

```python
# Utiliser des s√©lecteurs CSS pour de meilleures performances
soup.select('div.content')  # Plus rapide que find_all
soup.select_one('div.content')  # Plus rapide que find
```

---

## üöÄ 9. Exemple complet : Scraper une page web

```python
import requests
from bs4 import BeautifulSoup
import csv

def scraper_exemple():
    # R√©cup√©rer la page
    url = "https://example.com"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Extraire les donn√©es
    articles = []
    for article in soup.find_all('article'):
        title = article.find('h2')
        content = article.find('p')
        
        if title and content:
            articles.append({
                'titre': title.get_text().strip(),
                'contenu': content.get_text().strip()
            })
    
    # Sauvegarder en CSV
    with open('articles.csv', 'w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=['titre', 'contenu'])
        writer.writeheader()
        writer.writerows(articles)
    
    return articles
```

---

## üìã 10. R√©sum√© des m√©thodes principales

| M√©thode | Description | Exemple |
|---------|-------------|---------|
| `find()` | Premier √©l√©ment correspondant | `soup.find('div')` |
| `find_all()` | Tous les √©l√©ments correspondants | `soup.find_all('p')` |
| `select()` | S√©lecteur CSS | `soup.select('.class')` |
| `select_one()` | Premier √©l√©ment avec CSS | `soup.select_one('#id')` |
| `.text` | Texte de l'√©l√©ment | `element.text` |
| `.get()` | Attribut de mani√®re s√ªre | `element.get('href')` |
| `.parent` | √âl√©ment parent | `element.parent` |
| `.children` | Enfants directs | `element.children` |

---

## üéì Conclusion

BeautifulSoup est un outil puissant pour le web scraping. Les concepts cl√©s √† retenir :

1. **S√©lecteurs** : Utilisez `find()`, `find_all()`, `select()` selon vos besoins
2. **Navigation** : Ma√Ætrisez les relations parent-enfant-fr√®res
3. **Extraction** : Choisissez la bonne m√©thode pour extraire texte/attributs
4. **Gestion d'erreurs** : V√©rifiez toujours l'existence des √©l√©ments
5. **Performance** : Privil√©giez les s√©lecteurs CSS pour de grandes pages
